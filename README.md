# OpenSky Flight Tracker âœˆï¸

Tableau de bord temps rÃ©el des vols autour de l'aÃ©roport international de **Dubai (DXB)** utilisant Apache Kafka, Apache Spark et Streamlit.

> **Note** : Le projet ciblait initialement Ouagadougou (DFFD), mais a Ã©tÃ© reconfigurÃ© pour Dubai en raison du faible trafic aÃ©rien Ã  Ouagadougou (peu de vols dÃ©tectÃ©s dans l'API OpenSky Network).

## ğŸ—ï¸ Architecture

```
OpenSky API â†’ Kafka Producer â†’ Kafka Topic â†’ Spark Streaming â†’ Fichiers Parquet â†’ Streamlit Dashboard
                    â†“               â†“                â†“
              (30s interval)  (flights-data)   (AgrÃ©gations)
```

**Flux de donnÃ©es :**
1. **kafka_producer.py** : Collecte les vols dans un rayon de 100km autour de Dubai depuis l'API OpenSky
2. **Kafka Topic** : `flights-data` stocke les messages JSON
3. **spark_consumer.py** : Traite le stream en temps rÃ©el et Ã©crit dans `/tmp/flights_data/`
4. **dashboard.py** : Lit les fichiers Parquet et affiche les visualisations

## ğŸ“‹ PrÃ©requis

- **Python 3.12+**
- **Docker & Docker Compose** (pour Kafka)
- **Java 17** (pour Spark)
- Connexion internet (API OpenSky Network)

## ğŸš€ Installation & DÃ©marrage

### 1. PrÃ©parer l'environnement

```bash
# Cloner le projet
git clone <votre-repo>
cd opensky-flight-tracker

# CrÃ©er l'environnement virtuel
python3 -m venv venv
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 2. DÃ©marrer Kafka

```bash
# Lancer Kafka et Zookeeper avec Docker
docker-compose up -d

# VÃ©rifier que les conteneurs tournent
docker ps
```

### 3. Lancer l'application (mÃ©thode automatique)

```bash
# Tout en un seul script !
bash start.sh
```

Le script `start.sh` lance automatiquement :
- âœ… Le Kafka Producer
- âœ… Le Spark Consumer  
- âœ… Le Dashboard Streamlit

**AccÃ¨s :**
- ğŸ“Š Dashboard : http://localhost:8501
- ğŸ” Kafka UI : http://localhost:8080

**ArrÃªter :** Appuyez sur `Ctrl+C`

### Alternative : Lancement manuel (3 terminaux)

**Terminal 1 - Kafka Producer :**
```bash
source venv/bin/activate
./venv/bin/python kafka_producer.py
```

**Terminal 2 - Spark Consumer :**
```bash
source venv/bin/activate
bash run_spark.sh
```

**Terminal 3 - Dashboard Streamlit :**
```bash
source venv/bin/activate
./venv/bin/python -m streamlit run dashboard.py
```

## ğŸ“Š FonctionnalitÃ©s

### Kafka Producer
- âœ… Collecte des vols dans un rayon de 100km autour de Dubai (DXB)
- âœ… Calcul de distance depuis l'aÃ©roport
- âœ… Classification automatique : **arrivÃ©e**, **dÃ©part**, **stationnement**, **en_vol**
- âœ… Envoi vers le topic Kafka `flights-data` (intervalle 30s)
- âœ… Gestion des erreurs et retry automatique

### Spark Consumer
- âœ… Stream processing en temps rÃ©el avec PySpark 3.5.0
- âœ… Conversion des unitÃ©s (mÃ¨tres â†’ pieds, m/s â†’ km/h)
- âœ… AgrÃ©gations par fenÃªtre temporelle (2 minutes glissantes)
- âœ… Ã‰criture dans des fichiers Parquet pour partage avec Streamlit
- âœ… Statistiques par statut de vol
- âœ… DÃ©doublonnage par ICAO24

### Dashboard Streamlit
- âœ… **Carte interactive** des vols (Plotly Mapbox avec OpenStreetMap)
- âœ… **MÃ©triques en temps rÃ©el** : arrivÃ©es, dÃ©parts, stationnement, total
- âœ… **Graphiques** : distribution par statut, altitudes
- âœ… **Timeline** : Ã©volution du nombre de vols
- âœ… **Tableau dÃ©taillÃ©** : derniers vols avec callsign, pays, statut, altitude, vitesse
- âœ… **Auto-refresh** : toutes les 10 secondes (configurable)

## ğŸ› ï¸ Configuration

### Changer l'aÃ©roport surveillÃ©

Modifier dans `kafka_producer.py` :
```python
# CoordonnÃ©es de l'aÃ©roport (exemple : Paris CDG)
DUBAI_LAT = 49.0097
DUBAI_LON = 2.5479
RADIUS = 100  # km
```

### Ajuster l'intervalle de polling

Dans `kafka_producer.py`, ligne 162 :
```python
producer.run(interval=30)  # 30 secondes (recommandÃ© pour Ã©viter rate limit)
```

### Modifier le topic Kafka

Dans tous les fichiers :
```python
topic='flights-data'  # Nom du topic
```

## ğŸ“¦ Structure du Projet

```
opensky-flight-tracker/
â”œâ”€â”€ kafka_producer.py       # 165 lignes - Collecte API OpenSky â†’ Kafka
â”œâ”€â”€ spark_consumer.py       # 215 lignes - Traitement Spark â†’ Parquet
â”œâ”€â”€ dashboard.py            # 280 lignes - Dashboard Streamlit
â”œâ”€â”€ run_spark.sh            # Script helper pour Spark avec Java 17
â”œâ”€â”€ start.sh                # Lancement automatique des 3 composants
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ docker-compose.yml      # Kafka + Zookeeper
â”œâ”€â”€ check.sh                # VÃ©rification de l'environnement
â””â”€â”€ README.md              # Documentation complÃ¨te
```

## ğŸ› ProblÃ¨mes RencontrÃ©s & Solutions

### 1. âŒ Trafic aÃ©rien insuffisant Ã  Ouagadougou

**ProblÃ¨me :** L'API OpenSky Network retournait trÃ¨s peu de vols (0-2) autour de Ouagadougou (DFFD).

**Solution :** Changement pour l'aÃ©roport de **Dubai International (DXB)**, un des plus frÃ©quentÃ©s au monde (30-50 vols simultanÃ©s dans la zone).

### 2. âŒ `ModuleNotFoundError: No module named 'kafka'`

**ProblÃ¨me :** Les scripts n'utilisaient pas le Python du venv.

**Solution :**
```bash
# Installation correcte
pip install kafka-python-ng==2.2.2

# Modification des scripts start.sh et run_spark.sh
./venv/bin/python kafka_producer.py  # au lieu de python
```

### 3. âŒ Erreur Spark avec Java 17

**ProblÃ¨me :** IncompatibilitÃ© entre PySpark 3.5.0 et Spark 4.0.1 systÃ¨me (`/opt/spark`).

**Solution :**
```bash
# Dans run_spark.sh
unset SPARK_HOME  # DÃ©sactive le Spark systÃ¨me
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64

# Ajout d'options JVM dans spark_consumer.py
.config("spark.driver.extraJavaOptions", 
        "--add-opens=java.base/java.lang=ALL-UNNAMED ...")
```

### 4. âŒ `Distinct aggregations are not supported on streaming DataFrames`

**ProblÃ¨me :** `countDistinct()` n'est pas supportÃ© en mode streaming.

**Solution :**
```python
# Avant
countDistinct("callsign").alias("unique_flights")

# AprÃ¨s
approx_count_distinct("callsign").alias("unique_flights")
```

### 5. âŒ Streamlit n'affiche rien

**ProblÃ¨me :** Streamlit ne peut pas accÃ©der aux tables Spark en mÃ©moire (processus sÃ©parÃ©s).

**Solution :**
- Spark Ã©crit dans des **fichiers Parquet** : `/tmp/flights_data/*.parquet`
- Streamlit lit ces fichiers au lieu de se connecter Ã  Spark
- Les statistiques sont calculÃ©es directement dans le dashboard

### 6. âŒ `This query does not support recovering from checkpoint`

**ProblÃ¨me :** Checkpoints corrompus dans `/tmp/checkpoint/`.

**Solution :**
```bash
# Nettoyage automatique dans start.sh
rm -rf /tmp/checkpoint/* /tmp/flights_data

# Suppression de la config globale dans spark_consumer.py
# .config("spark.sql.streaming.checkpointLocation", "/tmp/checkpoint")  # âŒ
```

### 7. âŒ `Data source parquet does not support Complete output mode`

**ProblÃ¨me :** Les statistiques agrÃ©gÃ©es (mode "complete") ne peuvent pas Ãªtre Ã©crites en Parquet.

**Solution :**
- Vols : Ã©criture en **Parquet** (mode "append")
- Statistiques : calcul direct dans **Streamlit** Ã  partir des vols

## ğŸ” DÃ©pannage

### Kafka ne dÃ©marre pas

```bash
# RedÃ©marrer proprement
docker-compose down -v
docker-compose up -d

# VÃ©rifier les logs
docker-compose logs kafka
```

### Erreur Java avec Spark

```bash
# Installer Java 17
sudo apt install openjdk-17-jdk

# VÃ©rifier la version
java -version  # doit afficher 17.x

# DÃ©finir JAVA_HOME
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
```

### Aucun fichier Parquet crÃ©Ã©

```bash
# VÃ©rifier que Spark tourne
ps aux | grep spark_consumer

# Voir les logs
tail -f /tmp/spark.log

# VÃ©rifier les donnÃ©es Kafka
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic flights-data --from-beginning
```

### Dashboard vide ou erreur

```bash
# VÃ©rifier que les fichiers existent
ls -lh /tmp/flights_data/*.parquet

# VÃ©rifier les logs Streamlit
tail -f /tmp/streamlit.log

# Relancer proprement
bash start.sh
```

### Trop de vols / Performances

```python
# Dans dashboard.py, limiter la lecture
latest_files = sorted(parquet_files, key=os.path.getmtime, reverse=True)[:10]

# RÃ©duire la fenÃªtre temporelle
five_min_ago = pd.Timestamp.now() - pd.Timedelta(minutes=3)  # au lieu de 5
```

## ğŸ“ˆ DonnÃ©es OpenSky Network

### Limites de l'API

| Compte | RequÃªtes/jour | Recommandation |
|--------|---------------|----------------|
| Anonyme | 400 | Intervalle â‰¥ 30s |
| Gratuit | 4000 | Intervalle â‰¥ 10s |
| Premium | IllimitÃ© | Pas de limite |

**Inscription gratuite :** https://opensky-network.org/

### Structure des donnÃ©es

```json
{
  "icao24": "89643f",           // ID unique de l'avion
  "callsign": "UAE414",         // Indicatif du vol
  "origin_country": "United Arab Emirates",
  "latitude": 25.2532,          // Position GPS
  "longitude": 55.3657,
  "baro_altitude": 1234.5,      // Altitude en mÃ¨tres
  "velocity": 123.45,           // Vitesse en m/s
  "vertical_rate": -2.5,        // MontÃ©e/descente (m/s)
  "on_ground": false,           // Au sol ?
  "status": "dÃ©part"            // CalculÃ© par notre logique
}
```

## ğŸ“ Contexte AcadÃ©mique

**Projet rÃ©alisÃ© dans le cadre d'un cours de Big Data et Streaming en Temps RÃ©el**

### Concepts mis en pratique

- âœ… **Streaming temps rÃ©el** : Apache Kafka + Spark Structured Streaming
- âœ… **Message broker** : Publication/Souscription avec Kafka
- âœ… **Traitement distribuÃ©** : PySpark avec agrÃ©gations fenÃªtrÃ©es
- âœ… **APIs REST** : Consommation de l'API OpenSky Network
- âœ… **Visualisation** : Dashboard interactif avec Streamlit et Plotly
- âœ… **Conteneurisation** : Docker pour Kafka
- âœ… **Format columnar** : Parquet pour le partage de donnÃ©es

### Technologies utilisÃ©es

| Composant | Technologie | Version |
|-----------|-------------|---------|
| Message Broker | Apache Kafka | 3.8.1 |
| Stream Processing | Apache Spark | 3.5.0 (PySpark) |
| Python | Python | 3.12 |
| Dashboard | Streamlit | 1.29.0 |
| Visualisation | Plotly | 5.18.0 |
| Client Kafka | kafka-python-ng | 2.2.2 |
| Conteneurisation | Docker | Latest |

## ğŸ“ AmÃ©liorations Possibles

- [ ] Ajouter des **alertes** (vol en approche, turbulences)
- [ ] **PrÃ©dictions ML** : heure d'arrivÃ©e estimÃ©e, retards
- [ ] **Historique** : stockage PostgreSQL/MongoDB
- [ ] **Multi-aÃ©roports** : sÃ©lection dynamique dans Streamlit
- [ ] **Authentification** OpenSky : augmenter les limites API
- [ ] **CI/CD** : dÃ©ploiement automatisÃ© avec GitHub Actions
- [ ] **Kubernetes** : orchestration pour production
- [ ] **Tests unitaires** : pytest pour la logique mÃ©tier

## ğŸ“ Licence

MIT License - Libre d'utilisation pour projets acadÃ©miques et personnels.

## ğŸ¤ Contribution

Pull requests bienvenues ! Pour des changements majeurs, ouvrez d'abord une issue.

---

**Auteur** : Zia  
**Date** : 6 Novembre 2025  
**Projet** : OpenSky Flight Tracker - Real-time Aviation Monitoring  

**Technologies** : Kafka â€¢ Spark â€¢ Python â€¢ Streamlit â€¢ Docker â€¢ Parquet

## ğŸš€ Installation Rapide

### 1. Cloner le projet
```bash
git clone <votre-repo>
cd opensky-flight-tracker
```

### 2. CrÃ©er l'environnement virtuel
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 4. DÃ©marrer Kafka avec Docker
```bash
docker-compose up -d
```

VÃ©rifier que Kafka est actif :
```bash
docker ps
```

## ğŸ¯ Utilisation

### Lancer les 3 composants (dans 3 terminaux diffÃ©rents)

**Terminal 1 - Kafka Producer :**
```bash
source venv/bin/activate
python kafka_producer.py
```

**Terminal 2 - Spark Consumer :**
```bash
source venv/bin/activate
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
python spark_consumer.py
```

**Terminal 3 - Dashboard Streamlit :**
```bash
source venv/bin/activate
streamlit run dashboard.py
```

Le dashboard sera accessible sur : **http://localhost:8501**

## ğŸ“Š FonctionnalitÃ©s

### Kafka Producer
- âœ… Collecte des vols dans un rayon de 100km autour de Ouagadougou
- âœ… Calcul de distance depuis l'aÃ©roport
- âœ… Classification des vols (arrivÃ©e, dÃ©part, stationnement, en vol)
- âœ… Envoi vers le topic Kafka `flights-data`

### Spark Consumer
- âœ… Stream processing en temps rÃ©el
- âœ… Conversion des unitÃ©s (mÃ¨tres â†’ pieds, m/s â†’ km/h)
- âœ… AgrÃ©gations par fenÃªtre temporelle (2 minutes)
- âœ… Statistiques par statut de vol

### Dashboard Streamlit
- âœ… Carte interactive des vols (Plotly Mapbox)
- âœ… MÃ©triques en temps rÃ©el (arrivÃ©es, dÃ©parts, stationnement)
- âœ… Graphiques de distribution (statuts, altitudes)
- âœ… Timeline des statistiques
- âœ… Tableau dÃ©taillÃ© des vols

## ğŸ› ï¸ Configuration

### Zone de surveillance
Modifiez les constantes dans `kafka_producer.py` :
```python
OUAGA_LAT = 12.3532  # Latitude Ouagadougou
OUAGA_LON = -1.5124  # Longitude Ouagadougou
RADIUS = 100         # Rayon en km
```

### Intervalle de polling
Dans `kafka_producer.py`, ligne finale :
```python
producer.run(interval=30)  # 30 secondes
```

### Kafka Topic
Dans tous les fichiers, changez :
```python
topic='flights-data'  # Nom du topic
```

## ğŸ“¦ Structure du Projet

```
opensky-flight-tracker/
â”œâ”€â”€ kafka_producer.py       # 180 lignes - Producer Kafka
â”œâ”€â”€ spark_consumer.py       # 150 lignes - Consumer Spark
â”œâ”€â”€ dashboard.py            # 250 lignes - Dashboard Streamlit
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ docker-compose.yml      # Configuration Kafka
â””â”€â”€ README.md              # Ce fichier
```

## ğŸ” DÃ©pannage

### Kafka ne dÃ©marre pas
```bash
docker-compose down -v
docker-compose up -d
```

### Erreur Java avec Spark
Installer Java 17 :
```bash
sudo apt install openjdk-17-jdk
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
```

### Aucun vol dÃ©tectÃ©
- Zone Ouagadougou peut avoir peu de trafic
- Tester avec une zone plus frÃ©quentÃ©e (Paris, Londres)
- VÃ©rifier les limites de l'API OpenSky (400 req/jour sans compte)

### Dashboard Streamlit vide
1. VÃ©rifier que `spark_consumer.py` est lancÃ©
2. Attendre 2-3 minutes que Spark agrÃ¨ge des donnÃ©es
3. VÃ©rifier les logs dans la console Spark

## ğŸ“ˆ DonnÃ©es OpenSky Network

**Limites API :**
- Sans compte : 400 requÃªtes/jour
- Compte gratuit : 4000 requÃªtes/jour
- DÃ©lai recommandÃ© : 30+ secondes entre requÃªtes

**Champs principaux :**
- `callsign` : Indicatif du vol
- `origin_country` : Pays d'origine
- `latitude/longitude` : Position GPS
- `baro_altitude` : Altitude baromÃ©trique (mÃ¨tres)
- `velocity` : Vitesse (m/s)
- `vertical_rate` : Taux de montÃ©e/descente
- `on_ground` : Au sol (True/False)

## ğŸ“ Projet AcadÃ©mique

Ce projet est rÃ©alisÃ© dans le cadre d'un cours de **Big Data et Streaming en Temps RÃ©el**.

**Technologies Ã©tudiÃ©es :**
- Apache Kafka (message broker)
- Apache Spark Structured Streaming
- PySpark (Python API pour Spark)
- Streamlit (dashboards interactifs)
- API REST (OpenSky Network)
- Docker (conteneurisation)

## ğŸ“ Licence

MIT License - Libre d'utilisation pour projets acadÃ©miques et personnels.

## ğŸ¤ Contribution

Pull requests bienvenues ! Pour des changements majeurs, ouvrez d'abord une issue.

---

**Auteur** : Votre Nom  
**Date** : Novembre 2025  
**Contact** : votre.email@example.com
