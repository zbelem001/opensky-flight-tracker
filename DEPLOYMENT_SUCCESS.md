# âœ… DÃ©ploiement Docker RÃ©ussi - OpenSky Flight Tracker

## ğŸ“… Date du dÃ©ploiement
7 novembre 2025

## ğŸ‰ Statut
**TOUS LES SERVICES OPÃ‰RATIONNELS** âœ…

## ğŸ“Š Services dÃ©ployÃ©s

### Infrastructure
- âœ… **Zookeeper** - Port 2181 - Running
- âœ… **Kafka** - Port 9092 - Healthy
- âœ… **Kafka UI** - http://localhost:8080 - Running

### Application
- âœ… **Producer** - Envoie des vols Ã  Kafka toutes les 30s - Running
- âœ… **Spark Consumer** - Traite les donnÃ©es en streaming - Running
- âœ… **Dashboard Streamlit** - http://localhost:8501 - Running (health: starting)

## ğŸ”§ Configuration appliquÃ©e

### Corrections effectuÃ©es
1. âœ… Mise Ã  jour Dockerfile.spark pour utiliser Java 21 au lieu de Java 17
2. âœ… Correction des URLs Kafka : `kafka:29092` au lieu de `localhost:9092`
3. âœ… Modification de `kafka_producer.py` pour utiliser les variables d'environnement
4. âœ… Modification de `spark_consumer.py` pour utiliser les variables d'environnement

### Variables d'environnement configurÃ©es

#### Producer
```env
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=flights-data
FETCH_INTERVAL=30
```

#### Spark Consumer
```env
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=flights-data
FLIGHTS_DATA_PATH=/data/flights_data
```

## ğŸ“ˆ VÃ©rifications effectuÃ©es

### 1. Producer
```bash
sudo docker-compose logs --tail=20 producer
```
**RÃ©sultat** : âœ… Envoie des vols (FDB4PD, FDB1938, AFL526, etc.)

### 2. Spark Consumer
```bash
sudo docker-compose logs --tail=30 spark-consumer
```
**RÃ©sultat** : âœ… Traite les batches et affiche les donnÃ©es

### 3. Fichiers Parquet
```bash
sudo docker exec opensky-spark ls -lh /data/flights_data/
```
**RÃ©sultat** : âœ… Fichiers crÃ©Ã©s (9.5K, 9.4K, 2.2K)

### 4. Dashboard Streamlit
**URL** : http://localhost:8501  
**RÃ©sultat** : âœ… Accessible

## ğŸš€ Commandes de gestion

### DÃ©marrer
```bash
sudo docker-compose up -d
```

### ArrÃªter
```bash
sudo docker-compose down
```

### Voir les logs
```bash
# Tous les services
sudo docker-compose logs -f

# Un service spÃ©cifique
sudo docker-compose logs -f producer
sudo docker-compose logs -f spark-consumer
sudo docker-compose logs -f dashboard
```

### VÃ©rifier le statut
```bash
sudo docker-compose ps
```

### RedÃ©marrer un service
```bash
sudo docker-compose restart producer
```

### Reconstruire et redÃ©marrer
```bash
sudo docker-compose down
sudo docker-compose build
sudo docker-compose up -d
```

## ğŸ“ Volumes persistants

- `opensky-flights-data` : DonnÃ©es Parquet des vols
- `opensky-checkpoint` : Checkpoints Spark

### Sauvegarder les donnÃ©es
```bash
sudo docker run --rm -v opensky-flights-data:/data -v $(pwd):/backup ubuntu tar czf /backup/flights-data-backup.tar.gz /data
```

### Restaurer les donnÃ©es
```bash
sudo docker run --rm -v opensky-flights-data:/data -v $(pwd):/backup ubuntu tar xzf /backup/flights-data-backup.tar.gz -C /
```

## ğŸ” Monitoring

### Kafka UI
- **URL** : http://localhost:8080
- **FonctionnalitÃ©s** :
  - Voir les topics Kafka
  - Consulter les messages
  - Monitorer les consommateurs

### Dashboard Streamlit
- **URL** : http://localhost:8501
- **FonctionnalitÃ©s** :
  - Statistiques en temps rÃ©el
  - Statistiques quotidiennes
  - Graphiques interactifs
  - Distribution horaire des vols

## ğŸ› RÃ©solution de problÃ¨mes

### Le producer redÃ©marre en boucle
1. VÃ©rifier les logs : `sudo docker-compose logs producer`
2. VÃ©rifier que Kafka est healthy : `sudo docker-compose ps`
3. Attendre 30 secondes que Kafka dÃ©marre complÃ¨tement

### Le dashboard ne montre pas de donnÃ©es
1. VÃ©rifier que Spark crÃ©e les fichiers Parquet :
   ```bash
   sudo docker exec opensky-spark ls -lh /data/flights_data/
   ```
2. VÃ©rifier les logs de Spark : `sudo docker-compose logs spark-consumer`
3. Attendre quelques minutes pour que les donnÃ©es s'accumulent

### Erreur "Connection refused"
1. VÃ©rifier que Docker est dÃ©marrÃ© : `sudo systemctl status docker`
2. DÃ©marrer Docker si nÃ©cessaire : `sudo systemctl start docker`
3. RedÃ©marrer les services : `sudo docker-compose restart`

## ğŸ“ Notes importantes

1. **Permissions Docker** : Utilisez `sudo` pour toutes les commandes docker-compose
2. **Temps de dÃ©marrage** : Attendez 30-60 secondes aprÃ¨s `docker-compose up -d`
3. **AÃ©roport suivi** : Dubai International Airport (DXB)
4. **FrÃ©quence** : DonnÃ©es rÃ©cupÃ©rÃ©es toutes les 30 secondes
5. **Stockage** : Les donnÃ©es sont persistÃ©es dans des volumes Docker

## ğŸ¯ Prochaines Ã©tapes possibles

- [ ] Configurer un reverse proxy (nginx) pour le dashboard
- [ ] Ajouter des alertes (emails, Slack) pour les anomalies
- [ ] DÃ©ployer sur un cloud provider (AWS, Azure, GCP)
- [ ] Ajouter des mÃ©triques avec Prometheus + Grafana
- [ ] Configurer la sauvegarde automatique des donnÃ©es
- [ ] Ajouter l'authentification au dashboard Streamlit
- [ ] Optimiser les performances Spark (partitionnement, caching)

## ğŸ† SuccÃ¨s du dÃ©ploiement

**Tous les objectifs atteints** :
- âœ… Kafka opÃ©rationnel et accessible
- âœ… Producer envoie des donnÃ©es en continu
- âœ… Spark traite les donnÃ©es en streaming
- âœ… Dashboard Streamlit accessible et fonctionnel
- âœ… DonnÃ©es persistÃ©es dans Parquet
- âœ… Architecture scalable et containerisÃ©e
- âœ… Documentation complÃ¨te

**ğŸ‰ Le projet OpenSky Flight Tracker est maintenant dÃ©ployÃ© et opÃ©rationnel via Docker !**
